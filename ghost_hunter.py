"""
Advanced Ghost Hunter Web App
Complete Streamlit implementation with full workflow integration
"""

import os
import random
import sys
import tempfile
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import streamlit as st
import yaml

# Add src to path to import modules
sys.path.append(str(Path(__file__).parent))

try:
    from scripts.create_average_boxes import convert_all_to_boxes
    from scripts.dm4_to_png import export_dm4_bf_images_to_png
    from scripts.streamlit_labeller import (
        StreamlitLabellerState,
        get_label_statistics,
        load_existing_labels,
        save_label,
    )
    from src.inference import plot_embeddings
    from src.run import main as train_model
except ImportError as e:
    st.error(f"Error importing modules: {e}")
    st.stop()

# Page configuration
st.set_page_config(
    page_title="Ghost Hunter ML Pipeline",
    page_icon="üëª",
    layout="wide",
    initial_sidebar_state="expanded",
)


def initialize_session_state():
    """Initialize session state variables"""
    defaults = {
        "step": 1,
        "config": {},
        "temp_dir": tempfile.mkdtemp(),
        "conversion_done": False,
        "boxing_done": False,
        "labelling_done": False,
        "training_done": False,
        "inference_done": False,
        # Labelling-specific state
        "labeller_state": None,
        "current_label_file": None,
        "labelling_initialized": False,
        # Inference result
        "inference_plot_path": None,
    }

    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def main():
    """Main application function"""
    initialize_session_state()

    # Header
    st.title("üëª Ghost Hunter: Interactive ML Pipeline")
    st.markdown(
        "**Transform DM4 files ‚Üí Label data ‚Üí Train models ‚Üí Generate insights**"
    )

    # Sidebar with status indicators
    with st.sidebar:
        st.title("üöÄ Pipeline Status")

        # Status indicators
        st.write("### Status")
        status_icons = {
            "conversion_done": "‚úÖ Conversion Complete"
            if st.session_state.conversion_done
            else "‚è≥ Conversion Pending",
            "boxing_done": "‚úÖ Boxing Complete"
            if st.session_state.boxing_done
            else "‚è≥ Boxing Pending",
            "labelling_done": "‚úÖ Labelling Complete"
            if st.session_state.labelling_done
            else "‚è≥ Labelling Pending",
            "training_done": "‚úÖ Training Complete"
            if st.session_state.training_done
            else "‚è≥ Training Pending",
            "inference_done": "‚úÖ Inference Complete"
            if st.session_state.inference_done
            else "‚è≥ Inference Pending",
        }

        for status in status_icons.values():
            st.write(status)

    # Display all sections on one page
    setup_configuration()
    st.divider()

    dm4_conversion()
    st.divider()

    average_boxing()
    st.divider()

    data_labelling()
    st.divider()

    model_training()
    st.divider()

    inference_results()


def setup_configuration():
    """Step 1: Setup and Configuration"""
    st.header("‚öôÔ∏è Step 1: Setup & Configuration")

    # Create two columns for new project vs existing project
    st.subheader("Choose Your Path")
    col_left, col_right = st.columns(2)

    with col_left:
        st.markdown("### üÜï Create New Project")
        st.caption("Start a fresh project from scratch")

        project_name = st.text_input(
            "Enter a unique project name",
            value="my_ghost_hunter_project",
            key="project_name_new",
            help="Use only letters, numbers, underscores, and hyphens.",
        )

        # Validate project name
        project_name_valid = False
        if project_name:
            import re

            if not re.match(r"^[a-zA-Z0-9_-]+$", project_name):
                st.error("‚ùå Invalid characters in name")
            elif len(project_name) < 3:
                st.warning("‚ö†Ô∏è Name too short (min 3 chars)")
            else:
                st.success("‚úÖ Valid name")
                project_name_valid = True

        use_new_project = st.checkbox("Use this new project", key="use_new", value=True)

    with col_right:
        st.markdown("### üìÇ Load Existing Project")
        st.caption("Continue working on a previous project")

        # Get existing config files
        configs_dir = "configs"
        existing_configs = []
        if os.path.exists(configs_dir):
            existing_configs = [
                f.replace(".yaml", "")
                for f in os.listdir(configs_dir)
                if f.endswith(".yaml") and not f.startswith(".")
            ]

        if existing_configs:
            selected_config = st.selectbox(
                "Select an existing project",
                options=["", *sorted(existing_configs)],
                key="existing_project_select",
                help="Choose from previously created projects",
            )

            if selected_config:
                st.success(f"‚úÖ Selected: `{selected_config}`")
                # Load the config to show summary
                try:
                    config_path = os.path.join(configs_dir, f"{selected_config}.yaml")
                    with open(config_path) as f:
                        loaded_config = yaml.safe_load(f)

                    with st.expander("üìã Project Info"):
                        # Display data configuration
                        if "data" in loaded_config:
                            st.markdown("**üìÅ Data Configuration:**")
                            data_config = loaded_config["data"]
                            st.write(
                                f"- Data Directory: `{data_config.get('data_dir', 'N/A')}`"
                            )
                            st.write(
                                f"- Image Size: {data_config.get('image_size', 'N/A')}px"
                            )
                            st.write(
                                f"- Labels File: `{data_config.get('labels_file', 'N/A')}`"
                            )
                            st.write(
                                f"- Train/Val/Test: {data_config.get('train_ratio', 'N/A')}/{data_config.get('val_ratio', 'N/A')}/{data_config.get('test_ratio', 'N/A')}"
                            )

                        # Display model configuration
                        if "model" in loaded_config:
                            st.markdown("**üß† Model Configuration:**")
                            model_config = loaded_config["model"]
                            st.write(
                                f"- Model: {model_config.get('model_name', 'N/A')}"
                            )
                            st.write(
                                f"- Batch Size: {model_config.get('batch_size', 'N/A')}"
                            )
                            st.write(
                                f"- Channels: {model_config.get('in_channels', 'N/A')}"
                            )

                        # Display training configuration
                        st.markdown("**‚öôÔ∏è Training Configuration:**")
                        st.write(
                            f"- Device: {loaded_config.get('accelerator', 'N/A').upper()}"
                        )
                        st.write(f"- Task: {loaded_config.get('task', 'N/A')}")

                        if "optimizer" in loaded_config:
                            opt_config = loaded_config["optimizer"]
                            st.write(
                                f"- Optimizer: {opt_config.get('optimizer', 'N/A')}"
                            )
                            st.write(f"- Learning Rate: {opt_config.get('lr', 'N/A')}")
                            st.write(
                                f"- Weight Decay: {opt_config.get('weight_decay', 'N/A')}"
                            )

                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Could not load config details: {str(e)}")

            use_existing_project = st.checkbox(
                "Use this existing project", key="use_existing", value=False
            )
        else:
            st.info("‚ÑπÔ∏è No existing projects found")
            st.caption("Create a new project to get started")
            selected_config = None
            use_existing_project = False

    st.divider()

    # Determine which project to use
    if use_existing_project and selected_config:
        project_name = selected_config
        st.info(f"üîÑ Loading existing project: **{project_name}**")
        load_from_config = True
    elif use_new_project and project_name_valid:
        st.info(f"üÜï Creating new project: **{project_name}**")
        load_from_config = False
    else:
        st.warning(
            "‚ö†Ô∏è Please select either a new project name or an existing project to continue."
        )
        return

    # Check if project already exists
    png_path = f"data/png/{project_name}"
    boxed_path = f"data/boxed_png/{project_name}"
    project_exists = os.path.exists(png_path) or os.path.exists(boxed_path)

    if project_exists:
        st.info(
            f"‚ÑπÔ∏è **Existing project detected!** If PNG files and/or boxed images already exist for '{project_name}', you can skip those steps and proceed directly to labelling or training."
        )

        # Show what exists
        png_exists = (
            os.path.exists(png_path)
            and len([f for f in os.listdir(png_path) if f.endswith(".png")]) > 0
        )
        boxed_exists = (
            os.path.exists(boxed_path)
            and len([f for f in os.listdir(boxed_path) if f.endswith(".png")]) > 0
        )

        if png_exists:
            png_count = len([f for f in os.listdir(png_path) if f.endswith(".png")])
            st.success(f"‚úÖ Found {png_count} PNG files in `{png_path}`")

        if boxed_exists:
            boxed_count = len([f for f in os.listdir(boxed_path) if f.endswith(".png")])
            st.success(f"‚úÖ Found {boxed_count} boxed images in `{boxed_path}`")

    # File path input
    st.subheader("üìÅ Specify DM4 File Path")

    # Make DM4 optional if project exists
    help_text = "Example: /home/user/data/experiment.dm4"
    if project_exists:
        help_text += (
            " (Optional for existing projects - leave blank to skip conversion steps)"
        )

    dm4_file_path = st.text_input(
        "Enter the full path to your DM4 file",
        value="",
        key="dm4_file_path",
        help=help_text,
    )

    st.subheader("ü§ñ Training Parameters")

    # Load defaults from existing config if available
    default_device = "cpu"
    default_epochs = 50
    default_batch_size = 32
    default_lr = 0.0004

    if load_from_config and selected_config:
        try:
            config_path = os.path.join("configs", f"{selected_config}.yaml")
            with open(config_path) as f:
                loaded_config = yaml.safe_load(f)

            default_device = loaded_config.get("accelerator", "cpu")
            if "model" in loaded_config:
                default_batch_size = loaded_config["model"].get("batch_size", 32)
            if "optimizer" in loaded_config:
                default_lr = loaded_config["optimizer"].get("lr", 0.0004)

            st.caption(
                "‚ÑπÔ∏è Using parameters from existing config (you can modify them below)"
            )
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not load all parameters from config: {str(e)}")

    # Device selection
    col1, col2 = st.columns([2, 1])
    with col1:
        device_options = ["cpu", "cuda", "mps"]
        device_descriptions = {
            "cpu": "CPU - Compatible with all systems (slower)",
            "cuda": "CUDA - NVIDIA GPU acceleration (fastest, requires CUDA)",
            "mps": "MPS - Apple Silicon GPU acceleration (M1/M2 Macs)",
        }

        # Set default index based on loaded config
        default_device_index = (
            device_options.index(default_device)
            if default_device in device_options
            else 0
        )

        device = st.selectbox(
            "Training Device",
            options=device_options,
            index=default_device_index,
            format_func=lambda x: device_descriptions[x],
            key="device_select",
            help="Select the device for model training. CUDA requires NVIDIA GPU, MPS requires Apple Silicon.",
        )

    with col2:
        # Device availability check
        try:
            import torch

            if device == "cuda" and not torch.cuda.is_available():
                st.warning("‚ö†Ô∏è CUDA not available")
            elif device == "mps" and not torch.backends.mps.is_available():
                st.warning("‚ö†Ô∏è MPS not available")
            else:
                st.success(f"‚úÖ {device.upper()} ready")
        except ImportError:
            st.info("‚ÑπÔ∏è Install PyTorch to check device availability")

    max_epochs = st.number_input(
        "Max Epochs",
        value=default_epochs,
        min_value=1,
        key="max_epochs",
        help="Number of complete passes through the training data",
    )

    # Set default batch size index
    batch_size_options = [16, 32, 64, 128]
    default_batch_index = (
        batch_size_options.index(default_batch_size)
        if default_batch_size in batch_size_options
        else 1
    )

    batch_size = st.selectbox(
        "Batch Size",
        batch_size_options,
        index=default_batch_index,
        key="batch_size",
        help="Number of samples processed together. Larger = faster but needs more memory",
    )
    learning_rate = st.number_input(
        "Learning Rate",
        value=default_lr,
        format="%.6f",
        key="learning_rate",
        help="Step size for model weight updates. Typical range: 0.0001 - 0.001",
    )

    # Validate file path (optional for existing projects)
    dm4_file_valid = False
    n_cols = None  # Initialize dimension variables
    n_rows = None
    if dm4_file_path:
        if os.path.exists(dm4_file_path):
            if dm4_file_path.endswith(".dm4"):
                dm4_file_valid = True
                st.success(f"‚úÖ Valid DM4 file: `{os.path.basename(dm4_file_path)}`")
            else:
                st.error(
                    "‚ùå Invalid file type! Please provide a file with `.dm4` extension."
                )
                st.info(
                    "üí° Tip: Make sure your file path ends with `.dm4` (e.g., `/path/to/data.dm4`)"
                )
        else:
            st.error(f"‚ùå File not found at the specified path: `{dm4_file_path}`")
            st.info(
                "üí° Tips:\n- Check for typos in the file path\n- Use absolute paths (e.g., `/home/user/data.dm4`)\n- Ensure you have read permissions for the file"
            )
    elif not project_exists:
        st.warning(
            "‚ö†Ô∏è DM4 file path is required for new projects. Please provide a valid path above."
        )
        st.info("üí° If you're loading an existing project, the DM4 file is optional.")

    # Show DM4 info and images if valid path provided
    if dm4_file_valid:
        st.info("Preview: Random diffraction image and virtual image from DM4 file")
        temp_dm4_path = dm4_file_path

        # Get dataset info and show dimensions
        import py4DSTEM

        try:
            dataset = py4DSTEM.import_file(temp_dm4_path)  # type: ignore
            shape = dataset.data.shape  # type: ignore
            n_rows = shape[0]
            n_cols = shape[1]

            diffraction_image_size = dataset.data[0][0].shape  # type: ignore

            st.write(
                f"**Real space image dimensions:** {n_cols} x {n_rows} (scan positions)"
            )
            st.write(
                f"**Diffraction pattern size:** {diffraction_image_size[1]} x {diffraction_image_size[0]} (detector pixels)"
            )

            # Create a figure with two subplots side by side
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))

            # Load dataset and show random diffraction pattern
            random_i = random.randint(0, shape[0] - 1)
            random_j = random.randint(0, shape[1] - 1)
            diffraction_pattern = dataset[random_i, random_j].data  # type: ignore

            im1 = ax1.imshow(diffraction_pattern, cmap="gray")
            ax1.set_title(f"Random Diffraction Pattern\nat ({random_i}, {random_j})")
            ax1.set_xlabel("Detector X (pixels)")
            ax1.set_ylabel("Detector Y (pixels)")
            plt.colorbar(im1, ax=ax1, label="Intensity", fraction=0.046)

            # Create virtual image
            virtual_image = dataset.data.sum(axis=(2, 3))  # type: ignore

            im2 = ax2.imshow(virtual_image, cmap="gray")
            ax2.set_title("Virtual Image\n(summed intensity)")
            ax2.set_xlabel("Scan X")
            ax2.set_ylabel("Scan Y")
            plt.colorbar(im2, ax=ax2, label="Intensity", fraction=0.046)

            plt.tight_layout()
            st.pyplot(fig, width="content")
            plt.close(fig)
        except Exception as e:
            st.warning(f"Could not read DM4 file or display images: {e}")

    # Save configuration
    if st.button("üíæ Save Configuration & Proceed", type="primary"):
        # Validate project name before proceeding
        import re

        if not project_name or len(project_name) < 3:
            st.error("‚ùå Please enter a valid project name (at least 3 characters).")
            return
        if not re.match(r"^[a-zA-Z0-9_-]+$", project_name):
            st.error(
                "‚ùå Project name contains invalid characters. Use only letters, numbers, underscores, and hyphens."
            )
            return

        # For existing projects, try to auto-detect dimensions
        n_cols_detected = None
        n_rows_detected = None

        if project_exists:
            # Try to get dimensions from existing files
            if os.path.exists(png_path):
                png_files = [f for f in os.listdir(png_path) if f.endswith(".png")]
                if png_files:
                    # Get dimensions from last file
                    last_file = sorted(png_files)[-1]
                    parts = last_file.replace(".png", "").split("_")
                    if len(parts) >= 3:  # base_row_col format
                        try:
                            n_rows_detected = int(parts[-2]) + 1
                            n_cols_detected = int(parts[-1]) + 1
                        except ValueError:
                            st.warning(
                                "‚ö†Ô∏è Could not auto-detect dimensions from PNG filenames. Please check file naming."
                            )

            elif os.path.exists(boxed_path):
                boxed_files = [f for f in os.listdir(boxed_path) if f.endswith(".png")]
                if boxed_files:
                    # Get dimensions from last boxed file
                    last_file = sorted(boxed_files)[-1]
                    parts = last_file.replace(".png", "").split("_")
                    if len(parts) >= 2:  # row_col_boxsize format
                        try:
                            n_rows_detected = int(parts[0]) + 1
                            n_cols_detected = int(parts[1]) + 1
                        except ValueError:
                            st.warning(
                                "‚ö†Ô∏è Could not auto-detect dimensions from boxed filenames. Please check file naming."
                            )

        # Use detected dimensions or require DM4 file for new projects
        if n_cols_detected and n_rows_detected:
            n_cols = n_cols_detected
            n_rows = n_rows_detected
            st.info(
                f"‚úÖ Auto-detected dimensions from existing files: {n_cols} x {n_rows}"
            )
        elif not dm4_file_path or not dm4_file_valid:
            st.error("‚ùå Cannot proceed without valid DM4 file for new projects!")
            st.info(
                "üí° For new projects: Provide a valid DM4 file path above.\nüí° For existing projects: Make sure PNG or boxed files exist in the project directories."
            )
            return
        else:
            # n_cols and n_rows should have been set from DM4 file in the dm4_file_valid section
            # If not set, we cannot proceed
            if "n_cols" not in locals() or "n_rows" not in locals():
                st.error(
                    "‚ùå Could not determine array dimensions. Please check your DM4 file."
                )
                return

        config = {
            "project_name": project_name,
            "dm4_file_path": dm4_file_path if dm4_file_valid else "",
            "output_png_path": f"data/png/{project_name}",
            "boxed_png_path": f"data/boxed_png/{project_name}",
            "labelling_path": f"labelling/{project_name}_labels.yaml",
            "output_save_path": f"output/{project_name}/",
            "n_cols": n_cols,
            "n_rows": n_rows,
            "box_size": 3,  # Default, will be set in boxing section
            "sampling_space": 10,  # Default, will be set in labelling section
            "number_of_labels": 50,  # Default, will be set in labelling section
            "max_epochs": max_epochs,
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "device": device,  # Training device (cpu, cuda, mps)
        }
        st.session_state.config = config

        # Auto-mark steps as done if files exist
        if project_exists:
            png_exists = (
                os.path.exists(png_path)
                and len([f for f in os.listdir(png_path) if f.endswith(".png")]) > 0
            )
            boxed_exists = (
                os.path.exists(boxed_path)
                and len([f for f in os.listdir(boxed_path) if f.endswith(".png")]) > 0
            )

            if png_exists:
                st.session_state.conversion_done = True
            if boxed_exists:
                st.session_state.boxing_done = True

            # Check for completed labelling file
            labelling_path = str(config["labelling_path"])
            if os.path.exists(labelling_path):
                try:
                    labels_data = load_existing_labels(labelling_path)
                    num_labels = len(labels_data.get("labels", []))
                    if num_labels >= int(config["number_of_labels"]):  # type: ignore
                        st.session_state.labelling_done = True
                        st.success(
                            f"‚úÖ Found completed labelling file with {num_labels} labels"
                        )
                except Exception:
                    pass

            # Check for model checkpoint
            checkpoint_dir = f"checkpoints/{project_name}"
            if os.path.exists(checkpoint_dir):
                checkpoint_files = [
                    f for f in os.listdir(checkpoint_dir) if f.endswith(".ckpt")
                ]
                if checkpoint_files:
                    st.session_state.training_done = True
                    st.success(f"‚úÖ Found {len(checkpoint_files)} model checkpoint(s)")

        st.success("‚úÖ Configuration saved successfully!")

        # Provide navigation guidance based on what exists
        if st.session_state.training_done:
            st.info(
                "üëâ Existing model checkpoints found! You can proceed directly to Step 6: Inference"
            )
        elif st.session_state.labelling_done:
            st.info("üëâ Labelling completed! You can proceed to Step 5: Model Training")
        elif st.session_state.conversion_done and st.session_state.boxing_done:
            st.info(
                "üëâ Existing project loaded! You can proceed to Step 4: Data Labelling"
            )
        elif st.session_state.conversion_done:
            st.info("üëâ PNG files found! You can proceed to Step 3: Average Boxing")
        else:
            st.info("üëâ You can now proceed to Step 2: DM4 Conversion")


def dm4_conversion():
    """Step 2: DM4 to PNG Conversion"""
    st.header("üîÑ Step 2: DM4 to PNG Conversion")

    if not st.session_state.config:
        st.error("‚ùå Please complete Step 1 first!")
        return

    config = st.session_state.config

    # Display current settings
    with st.expander("Current Configuration", expanded=False):
        st.json(config)

    st.subheader("üõ†Ô∏è Conversion Settings")
    crop_images = st.checkbox(
        "Crop Images",
        key="crop_images",
        help="Enable to crop diffraction patterns to a specific region",
    )

    crop_values = None
    x_min = 0
    x_max = 512
    y_min = 0
    y_max = 512

    if crop_images:
        st.write("**Crop Parameters (x_min, x_max, y_min, y_max):**")
        st.caption("‚ö†Ô∏è Make sure crop values are within your image dimensions!")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            x_min = st.number_input("X Min", value=0, min_value=0, key="x_min")
        with col2:
            x_max = st.number_input("X Max", value=512, min_value=1, key="x_max")
        with col3:
            y_min = st.number_input("Y Min", value=0, min_value=0, key="y_min")
        with col4:
            y_max = st.number_input("Y Max", value=512, min_value=1, key="y_max")

        # Validate crop values
        if x_min >= x_max:
            st.error("‚ùå X Min must be less than X Max!")
        if y_min >= y_max:
            st.error("‚ùå Y Min must be less than Y Max!")
        if (x_max - x_min) < 10 or (y_max - y_min) < 10:
            st.warning("‚ö†Ô∏è Crop region is very small. Make sure this is intentional.")

        crop_values = (x_min, x_max, y_min, y_max)

    if st.button("üöÄ Start DM4 Conversion", type="primary"):
        if not config.get("dm4_file_path"):
            st.error("‚ùå No DM4 file path found in configuration!")
            st.info(
                "üí° Please go back to Step 1 and provide a valid DM4 file path, then save the configuration."
            )
            return

        # Validate crop parameters if cropping is enabled
        if crop_images and (x_min >= x_max or y_min >= y_max):
            st.error(
                "‚ùå Invalid crop parameters! Please fix the values above before proceeding."
            )
            return

        try:
            # Use the file path directly - no need to copy
            dm4_file_path = config["dm4_file_path"]

            if not os.path.exists(dm4_file_path):
                st.error(f"‚ùå DM4 file not found at: `{dm4_file_path}`")
                st.info(
                    "üí° The file may have been moved or deleted. Please update the path in Step 1."
                )
                return

            # Progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()

            status_text.text(
                "üîÑ Converting DM4 to PNG format... This may take a few minutes."
            )
            progress_bar.progress(50)

            # Call conversion function directly with the file path
            export_dm4_bf_images_to_png(
                dm4_file_path,
                config["output_png_path"],
                crop=crop_images,
                crop_values=crop_values,
            )

            progress_bar.progress(100)
            status_text.text("‚úÖ Conversion completed successfully!")

            st.session_state.conversion_done = True
            st.success("üéâ DM4 conversion completed! Ready for average boxing.")

        except Exception as e:
            st.error(f"‚ùå Error during conversion: {str(e)}")


def average_boxing():
    """Step 3: Average Boxing"""
    st.header("üì¶ Step 3: Average Boxing")

    if not st.session_state.config:
        st.error("‚ùå Please complete previous steps first!")
        return

    if not st.session_state.conversion_done:
        st.warning("‚ö†Ô∏è Please complete DM4 conversion first!")
        return

    config = st.session_state.config

    # Display current settings
    with st.expander("Current Configuration", expanded=False):
        st.json(config)

    st.subheader("üì¶ Boxing Configuration")

    # Box size slider
    box_size = st.slider(
        "Box Size",
        min_value=1,
        max_value=5,
        value=config.get("box_size", 3),
        key="box_size_slider",
        help="Size of the averaging box for creating averaged images",
    )

    # Update config with selected box size
    st.session_state.config["box_size"] = box_size

    col1, col2 = st.columns(2)

    with col1:
        st.info(
            f"""
        **Input Settings:**
        - üìÅ PNG Directory: `{config["output_png_path"]}`
        - ÔøΩ Box Size: {config["box_size"]}
        - ÔøΩ Array Length: Auto-detected from filenames
        """
        )

    with col2:
        st.info(
            f"""
        **Output Settings:**
        - üìÅ Output Directory: `{config["boxed_png_path"]}`
        - üñºÔ∏è Processing: Max values with {config["box_size"]}x{config["box_size"]} boxes
        """
        )

        st.subheader("‚ÑπÔ∏è About Boxing")
        st.write(
            """
        **Average boxing** creates averaged images from neighboring regions:
        - Takes a box of images (e.g., 3x3 grid)
        - Computes max/average values across the box
        - Reduces noise and enhances features
        - Essential preprocessing step for labelling
        """
        )

    if st.button("üöÄ Start Average Boxing", type="primary"):
        # Validate input directory
        if not os.path.exists(config["output_png_path"]):
            st.error(f"‚ùå Input directory not found: `{config['output_png_path']}`")
            st.info(
                "üí° Please complete Step 2 (DM4 Conversion) first to generate PNG files."
            )
            return

        # Check for PNG files
        png_files = [
            f for f in os.listdir(config["output_png_path"]) if f.endswith(".png")
        ]
        if len(png_files) == 0:
            st.error(f"‚ùå No PNG files found in `{config['output_png_path']}`")
            st.info(
                "üí° Please complete Step 2 (DM4 Conversion) first to generate PNG files."
            )
            return

        # Validate box size
        if config["box_size"] < 1:
            st.error("‚ùå Box size must be at least 1!")
            return

        # Check if output would have enough images
        expected_output = (config["n_rows"] // config["box_size"]) * (
            config["n_cols"] // config["box_size"]
        )
        if expected_output < 10:
            st.warning(
                f"‚ö†Ô∏è Box size of {config['box_size']} will result in only {expected_output} output images. Consider using a smaller box size."
            )
            if not st.checkbox(
                "I understand and want to proceed anyway", key="confirm_small_output"
            ):
                return

        try:
            if not os.path.exists(config["output_png_path"]):
                st.error(
                    "‚ùå PNG directory not found! Please complete DM4 conversion first."
                )
                return

            # Count PNG files
            png_files = [
                f for f in os.listdir(config["output_png_path"]) if f.endswith(".png")
            ]
            if len(png_files) == 0:
                st.error("‚ùå No PNG files found in the output directory!")
                return

            st.info(f"üìä Found {len(png_files)} PNG files to process")

            # Progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()

            status_text.text("üì¶ Initializing boxing process...")
            progress_bar.progress(10)

            # Ensure output directory exists
            os.makedirs(config["boxed_png_path"], exist_ok=True)

            progress_bar.progress(25)
            status_text.text("üì¶ Creating averaged boxes... (This may take a while)")

            # Call boxing function
            convert_all_to_boxes(
                stem_image_dir=config["output_png_path"],
                output_dir=config["boxed_png_path"],
                box_size=config["box_size"],
                n_cols=config["n_cols"],
                n_rows=config["n_rows"],
            )

            progress_bar.progress(100)
            status_text.text("‚úÖ Boxing completed successfully!")

            st.session_state.boxing_done = True
            st.success("üéâ Average boxing completed! Ready for data labelling.")

            # Show results summary
            boxed_files = [
                f for f in os.listdir(config["boxed_png_path"]) if f.endswith(".png")
            ]
            st.info(f"üìä Generated {len(boxed_files)} boxed images")

        except Exception as e:
            st.error(f"‚ùå Error during boxing: {str(e)}")
            st.write("**Debugging info:**")
            st.write(f"- Input directory: {config['output_png_path']}")
            st.write(f"- Output directory: {config['boxed_png_path']}")
            st.write(f"- Box size: {config['box_size']}")
            st.write("- Array length: Auto-detected from filenames")


def data_labelling():
    """Step 4: Data Labelling - Streamlit Native Interface"""
    st.header("üè∑Ô∏è Step 4: Data Labelling")

    if not st.session_state.config:
        st.error("‚ùå Configuration not found!")
        st.info("üí° Please complete Step 1 (Setup & Configuration) first.")
        return

    if not st.session_state.boxing_done:
        st.warning("‚ö†Ô∏è Boxing step not completed!")
        st.info(
            "üí° Please complete Step 3 (Average Boxing) before labelling. You need boxed images to label."
        )
        return

    config = st.session_state.config

    # Check if boxed images exist
    if not os.path.exists(config["boxed_png_path"]):
        st.error(f"‚ùå Boxed images directory not found: `{config['boxed_png_path']}`")
        st.info("üí° Please complete Step 3 (Average Boxing) to generate boxed images.")
        return

    boxed_files = [
        f for f in os.listdir(config["boxed_png_path"]) if f.endswith(".png")
    ]
    if len(boxed_files) == 0:
        st.error(f"‚ùå No boxed images found in `{config['boxed_png_path']}`")
        st.info("üí° Please complete Step 3 (Average Boxing) to generate boxed images.")
        return

    # Check if labelling is already complete
    if os.path.exists(config["labelling_path"]):
        try:
            labels_data = load_existing_labels(config["labelling_path"])
            existing_num_labels = len(labels_data.get("labels", []))
            if existing_num_labels > 0:
                st.info(
                    f"‚ÑπÔ∏è Found existing labels file with {existing_num_labels} labels. You can continue labelling or proceed to training if complete."
                )
        except Exception:
            pass

    # Display configuration
    st.subheader("üìã Labelling Configuration")

    # Labelling parameter sliders
    sampling_interval = st.slider(
        "Sampling Interval",
        min_value=1,
        max_value=50,
        value=config.get("sampling_space", 10),
        key="sampling_interval",
        help="Grid spacing for initial sparse sampling. Smaller = more initial labels, longer setup time.",
    )
    number_of_labels = st.slider(
        "Number of Labels",
        min_value=10,
        max_value=1000,
        value=config.get("number_of_labels", 50),
        key="number_of_labels",
        help="Total number of labels to assign. More labels = better training, but more work.",
    )

    # Validate labelling parameters
    if number_of_labels > len(boxed_files):
        st.error(
            f"‚ùå Number of labels ({number_of_labels}) exceeds available images ({len(boxed_files)})!"
        )
        st.info(f"üí° Please reduce the number of labels to {len(boxed_files)} or less.")
        return

    # Calculate expected sparse samples
    expected_sparse = (config["n_rows"] // sampling_interval) * (
        config["n_cols"] // sampling_interval
    )
    if expected_sparse > number_of_labels:
        st.warning(
            f"‚ö†Ô∏è Sampling interval ({sampling_interval}) will generate ~{expected_sparse} samples, which exceeds your target of {number_of_labels} labels."
        )
        st.info(
            f"üí° Consider increasing the sampling interval to at least {int(np.sqrt(config['n_rows'] * config['n_cols'] / number_of_labels))} for efficiency."
        )
    elif expected_sparse < number_of_labels * 0.3:
        st.warning(
            f"‚ö†Ô∏è Sampling interval ({sampling_interval}) will only generate ~{expected_sparse} initial samples. Most labelling will use binary search refinement."
        )
        st.info(
            "üí° Consider decreasing the sampling interval for more uniform coverage."
        )

    # Update config with selected parameters
    st.session_state.config["sampling_space"] = sampling_interval
    st.session_state.config["number_of_labels"] = number_of_labels

    col1, col2 = st.columns(2)

    with col1:
        st.info(
            f"""
        **Current Settings:**
        - üìÅ Data Path: `{config["boxed_png_path"]}`
        - üéØ Sampling Space: {config["sampling_space"]}
        - üî¢ Number of Labels: {config["number_of_labels"]}
        """
        )

    with col2:
        st.info(
            f"""
        **Output:**
        - üìÑ Labels File: `{config["labelling_path"]}`
        """
        )

    # Initialize labeller state if needed
    if (
        st.button("üöÄ Initialize Labelling Session", type="primary")
        or st.session_state.labelling_initialized
    ):
        try:
            # Ensure labelling directory exists
            os.makedirs(os.path.dirname(config["labelling_path"]), exist_ok=True)

            # Initialize labeller state only once
            if not st.session_state.labelling_initialized:
                st.session_state.labeller_state = StreamlitLabellerState(
                    file_path=config["boxed_png_path"],
                    output_file=config["labelling_path"],
                    labels_to_assign=config["number_of_labels"],
                    step=config["sampling_space"],
                )
                st.session_state.labelling_initialized = True
                st.rerun()

            labeller = st.session_state.labeller_state

            # Check if labelling is complete
            if labeller.is_complete():
                st.success("üéâ All labels have been assigned!")
                st.session_state.labelling_done = True

                # Show final heatmap
                st.subheader("üìä Final Label Distribution")
                fig, ax = plt.subplots(figsize=(8, 6))
                final_heatmap = labeller.save_final_heatmap()
                cmap = plt.get_cmap("viridis", 4)
                im = ax.imshow(final_heatmap, cmap=cmap, vmin=0, vmax=3)
                ax.set_title("Final Label Map")
                ax.axis("off")
                plt.colorbar(
                    im,
                    ax=ax,
                    ticks=["No Label", "Horizontal", "Vertical", "No Polarisation"],
                    label="Label",
                    fraction=0.046,
                )
                plt.tight_layout()
                st.pyplot(fig, use_container_width=False)
                plt.close(fig)

                # Show statistics
                st.subheader("üìà Label Statistics")
                label_stats = get_label_statistics(config["labelling_path"])
                for label, count in label_stats.items():
                    st.write(f"- **{label}**: {count}")

                return

            # Get next file to label
            if st.session_state.current_label_file is None:
                next_file = labeller.get_next_file()
                if next_file:
                    st.session_state.current_label_file = next_file
                else:
                    st.error("‚ùå Could not get next file to label")
                    return

            current_file = st.session_state.current_label_file

            # Progress bar
            current, total = labeller.get_progress()
            st.progress(current / total)
            st.write(f"**Progress: {current} / {total} labels assigned**")

            # Display current heatmap and image side by side
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("üó∫Ô∏è Label Heatmap")
                fig, ax = plt.subplots(figsize=(5, 5))
                cmap = plt.get_cmap("viridis", 4)
                im = ax.imshow(labeller.sparse_array, cmap=cmap, vmin=0, vmax=3)

                # Highlight current position
                pos = labeller.get_current_position()
                if pos:
                    i, j = pos
                    ax.plot(
                        j,
                        i,
                        marker="s",
                        color="red",
                        markersize=10,
                        markeredgewidth=2,
                        markeredgecolor="black",
                    )

                ax.set_title("Current Labelling Progress", fontsize=10)
                ax.axis("off")
                plt.tight_layout()
                st.pyplot(fig, width="stretch")
                plt.close(fig)

            with col2:
                st.subheader("üñºÔ∏è Current Image")
                st.write(f"**File:** `{current_file}`")

                # Load and display image with caching
                img_path = os.path.join(config["boxed_png_path"], current_file)
                if os.path.exists(img_path):
                    # Use st.image directly with file path (faster than loading with PIL)
                    st.image(img_path, width="stretch")
                else:
                    st.error(f"‚ùå Image not found: {img_path}")

            # Labelling buttons
            st.subheader("üè∑Ô∏è Assign Label")
            st.write("**Choose the label for this image:**")

            col1, col2, col3 = st.columns(3)

            with col1:
                if st.button(
                    "üî¥ Horizontal Polarisation",
                    key="label_horizontal",
                    width="stretch",
                ):
                    save_label(current_file, config["labelling_path"], "horizontal")
                    labeller.update_sparse_array(1)
                    st.session_state.current_label_file = None
                    st.rerun()

            with col2:
                if st.button(
                    "üü¢ Vertical Polarisation", key="label_vertical", width="stretch"
                ):
                    save_label(current_file, config["labelling_path"], "vertical")
                    labeller.update_sparse_array(2)
                    st.session_state.current_label_file = None
                    st.rerun()

            with col3:
                if st.button(
                    "üü° No Observable Polarisation", key="label_none", width="stretch"
                ):
                    save_label(current_file, config["labelling_path"], "na")
                    labeller.update_sparse_array(3)
                    st.session_state.current_label_file = None
                    st.rerun()

            # Option to reset labelling
            st.divider()
            if st.button("üîÑ Reset Labelling Session", type="secondary"):
                st.session_state.labeller_state = None
                st.session_state.current_label_file = None
                st.session_state.labelling_initialized = False
                st.warning(
                    "‚ö†Ô∏è Labelling session reset. Note: Previously saved labels in the YAML file are preserved."
                )
                st.rerun()

        except FileNotFoundError as e:
            st.error(f"‚ùå Error: {str(e)}")
            st.info("üí° Make sure you have completed the average boxing step first.")
        except Exception as e:
            st.error(f"‚ùå Error during labelling: {str(e)}")
            import traceback

            st.code(traceback.format_exc())

    # Show existing labels if file exists
    if os.path.exists(config["labelling_path"]):
        with st.expander("üìä View Existing Labels"):
            try:
                labels_data = load_existing_labels(config["labelling_path"])
                if labels_data and "labels" in labels_data:
                    num_labels = len(labels_data["labels"])
                    st.write(f"**Total labels saved:** {num_labels}")

                    # Show statistics
                    label_stats = get_label_statistics(config["labelling_path"])
                    st.write("**Label Distribution:**")
                    for label, count in label_stats.items():
                        st.write(f"- {label}: {count}")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Could not read labels file: {str(e)}")


def model_training():
    """Step 4: Model Training"""
    st.header("ü§ñ Step 4: Model Training")

    if not st.session_state.config:
        st.error("‚ùå Configuration not found!")
        st.info("üí° Please complete Step 1 (Setup & Configuration) first.")
        return

    config = st.session_state.config

    # Validate labels file exists (more lenient - check file, not just session state)
    if not os.path.exists(config["labelling_path"]):
        st.error(f"‚ùå Labels file not found: `{config['labelling_path']}`")
        st.info(
            "üí° Please complete Step 4 (Data Labelling) to generate the labels file."
        )

        # Still show warning about session state if that's the issue
        if not st.session_state.labelling_done:
            st.warning("‚ö†Ô∏è Labelling step not marked as complete in this session.")
        return

    # Check number of labels
    try:
        labels_data = load_existing_labels(config["labelling_path"])
        num_labels = len(labels_data.get("labels", []))

        if num_labels < 10:
            st.error(f"‚ùå Insufficient labels! Found only {num_labels} labels.")
            st.info(
                "üí° You need at least 10 labels for training. Please complete the labelling step."
            )
            return
        elif num_labels < 30:
            st.warning(
                f"‚ö†Ô∏è Low number of labels ({num_labels}). Training may not produce good results."
            )
            st.info(
                "üí° Consider labelling more images (recommended: 50+) for better model performance."
            )
        else:
            st.success(f"‚úÖ Found {num_labels} labels - good for training!")

        # Check label distribution
        label_stats = get_label_statistics(config["labelling_path"])
        if len(label_stats) < 2:
            st.error(
                "‚ùå Only one label type found! You need at least 2 different label types for classification."
            )
            st.info("üí° Please add more diverse labels in the labelling step.")
            return

        # Check for imbalanced labels
        max_count = max(label_stats.values())
        min_count = min(label_stats.values())
        if max_count > min_count * 5:
            st.warning(
                "‚ö†Ô∏è Imbalanced label distribution detected! Some labels are 5x more common than others."
            )
            st.info(
                "üí° Consider labelling more images of underrepresented classes for better model balance."
            )
            with st.expander("View Label Distribution"):
                for label, count in label_stats.items():
                    st.write(f"- {label}: {count}")

    except Exception as e:
        st.error(f"‚ùå Could not validate labels: {str(e)}")
        return

    st.subheader("‚öôÔ∏è Training Configuration")
    col1, col2 = st.columns(2)

    with col1:
        st.info(
            f"""
        **Model Settings:**
        - üß† Model: ThreeLayerCnn
        - ÔøΩÔ∏è Device: {config.get("device", "cpu").upper()}
        - üìä Max Epochs: {config["max_epochs"]}
        - üì¶ Batch Size: {config["batch_size"]}
        - üìà Learning Rate: {config["learning_rate"]}
        """
        )

    with col2:
        st.info(
            """
        **Data Configuration:**
        - üéØ Train Ratio: 80%
        - ‚úÖ Validation Ratio: 10%
        - üß™ Test Ratio: 10%
        - üñºÔ∏è Image Size: 256x256
        """
        )

    if st.button("üöÄ Start Model Training", type="primary"):
        # Validate device availability before training
        selected_device = config.get("device", "cpu")
        try:
            import torch

            if selected_device == "cuda" and not torch.cuda.is_available():
                st.error("‚ùå CUDA device selected but not available!")
                st.info(
                    "üí° Options:\n- Install CUDA and PyTorch with CUDA support\n- Change device to 'cpu' in Step 1 and re-save configuration"
                )
                return
            elif selected_device == "mps" and not torch.backends.mps.is_available():
                st.error("‚ùå MPS device selected but not available!")
                st.info(
                    "üí° Options:\n- MPS requires Apple Silicon Mac (M1/M2)\n- Change device to 'cpu' in Step 1 and re-save configuration"
                )
                return
        except ImportError:
            if selected_device != "cpu":
                st.warning(
                    f"‚ö†Ô∏è Cannot verify {selected_device.upper()} availability (PyTorch not imported). Training will attempt to use {selected_device}."
                )

        # Initialize variables before try block to avoid unbound errors
        config_file_path = f"configs/{config['project_name']}.yaml"
        training_config = None

        try:
            # Create config file for training
            training_config = create_training_config(config)

            # Ensure configs directory exists
            os.makedirs("configs", exist_ok=True)

            # Save config file
            with open(config_file_path, "w") as f:
                yaml.dump(training_config, f, default_flow_style=False)

            progress_bar = st.progress(0)
            status_text = st.empty()

            status_text.text(
                f"üöÄ Initializing training on {selected_device.upper()}..."
            )
            progress_bar.progress(10)

            status_text.text("üß† Training model... (This may take a while)")
            progress_bar.progress(25)

            # Call training function
            train_model(f"{config['project_name']}.yaml")

            progress_bar.progress(100)
            status_text.text("‚úÖ Training completed successfully!")

            st.session_state.training_done = True
            st.success("üéâ Model training completed! Ready for inference.")

            # Display training statistics
            display_training_stats(config)

        except Exception as e:
            st.error(f"‚ùå Error during training: {str(e)}")
            st.write("**Debugging info:**")
            st.write(f"- Config file path: {config_file_path}")
            if training_config is not None:
                st.write(f"- Training config: {training_config}")

    # Display training statistics if training is complete
    if st.session_state.training_done:
        with st.expander("üìä View Training Statistics", expanded=False):
            display_training_stats(config)


def display_training_stats(config):
    """Display training statistics from PyTorch Lightning logs"""
    st.subheader("üìä Training Statistics")

    # Find the most recent lightning logs
    lightning_logs_dir = "lightning_logs"

    if not os.path.exists(lightning_logs_dir):
        st.info("‚ÑπÔ∏è No training logs found yet.")
        return

    # Get all version directories and sort by modification time
    version_dirs = [
        d for d in os.listdir(lightning_logs_dir) if d.startswith("version_")
    ]
    if not version_dirs:
        st.info("‚ÑπÔ∏è No training logs found yet.")
        return

    # Get the most recent version directory
    version_dirs_full = [os.path.join(lightning_logs_dir, d) for d in version_dirs]
    latest_log_dir = max(version_dirs_full, key=os.path.getmtime)
    metrics_file = os.path.join(latest_log_dir, "metrics.csv")

    if not os.path.exists(metrics_file):
        st.info("‚ÑπÔ∏è No metrics file found yet.")
        return

    try:
        import pandas as pd

        # Read metrics CSV
        df = pd.read_csv(metrics_file)

        # Display key metrics
        col1, col2, col3 = st.columns(3)

        # Get final metrics
        if "train_loss" in df.columns:
            final_train_loss = df["train_loss"].dropna().iloc[-1]
            with col1:
                st.metric("Final Train Loss", f"{final_train_loss:.4f}")

        if "val_loss" in df.columns:
            final_val_loss = df["val_loss"].dropna().iloc[-1]
            best_val_loss = df["val_loss"].min()
            with col2:
                st.metric("Final Val Loss", f"{final_val_loss:.4f}")
                st.metric("Best Val Loss", f"{best_val_loss:.4f}")

        if "train_acc" in df.columns:
            final_train_acc = df["train_acc"].dropna().iloc[-1]
            with col3:
                st.metric("Final Train Accuracy", f"{final_train_acc:.2%}")

        if "val_acc" in df.columns:
            final_val_acc = df["val_acc"].dropna().iloc[-1]
            best_val_acc = df["val_acc"].max()
            with col3:
                st.metric("Final Val Accuracy", f"{final_val_acc:.2%}")
                st.metric("Best Val Accuracy", f"{best_val_acc:.2%}")

        # Plot training curves
        st.write("### üìà Training Curves")

        # Loss plot
        if "train_loss" in df.columns or "val_loss" in df.columns:
            fig, ax = plt.subplots(figsize=(10, 4))

            if "train_loss" in df.columns:
                train_loss_clean = df[["epoch", "train_loss"]].dropna()
                ax.plot(
                    train_loss_clean["epoch"],
                    train_loss_clean["train_loss"],
                    label="Train Loss",
                    marker="o",
                    markersize=3,
                )

            if "val_loss" in df.columns:
                val_loss_clean = df[["epoch", "val_loss"]].dropna()
                ax.plot(
                    val_loss_clean["epoch"],
                    val_loss_clean["val_loss"],
                    label="Validation Loss",
                    marker="s",
                    markersize=3,
                )

            ax.set_xlabel("Epoch")
            ax.set_ylabel("Loss")
            ax.set_title("Training and Validation Loss")
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close(fig)

        # Accuracy plot
        if "train_acc" in df.columns or "val_acc" in df.columns:
            fig, ax = plt.subplots(figsize=(10, 4))

            if "train_acc" in df.columns:
                train_acc_clean = df[["epoch", "train_acc"]].dropna()
                ax.plot(
                    train_acc_clean["epoch"],
                    train_acc_clean["train_acc"] * 100,
                    label="Train Accuracy",
                    marker="o",
                    markersize=3,
                )

            if "val_acc" in df.columns:
                val_acc_clean = df[["epoch", "val_acc"]].dropna()
                ax.plot(
                    val_acc_clean["epoch"],
                    val_acc_clean["val_acc"] * 100,
                    label="Validation Accuracy",
                    marker="s",
                    markersize=3,
                )

            ax.set_xlabel("Epoch")
            ax.set_ylabel("Accuracy (%)")
            ax.set_title("Training and Validation Accuracy")
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close(fig)

        # Show full metrics table
        if st.checkbox("Show detailed metrics table"):
            st.dataframe(df, use_container_width=True)

    except Exception as e:
        st.warning(f"‚ö†Ô∏è Could not load training statistics: {str(e)}")


def inference_results():
    """Step 5: Inference and Results"""
    st.header("üìä Step 5: Inference & Results")

    if not st.session_state.config:
        st.error("‚ùå Configuration not found!")
        st.info("üí° Please complete Step 1 (Setup & Configuration) first.")
        return

    config = st.session_state.config

    # Check for model checkpoints (more lenient - check files, not just session state)
    checkpoint_dir = f"checkpoints/{config['project_name']}"
    if not os.path.exists(checkpoint_dir):
        st.error(f"‚ùå Checkpoint directory not found: `{checkpoint_dir}`")
        st.info(
            "üí° Please complete Step 5 (Model Training) to generate model checkpoints."
        )

        if not st.session_state.training_done:
            st.warning("‚ö†Ô∏è Training step not marked as complete in this session.")
        return

    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith(".ckpt")]
    if not checkpoint_files:
        st.error(f"‚ùå No checkpoint files found in `{checkpoint_dir}`")
        st.info(
            "üí° Please complete Step 5 (Model Training) to generate model checkpoints."
        )
        return

    # Display available checkpoints
    st.success(f"‚úÖ Found {len(checkpoint_files)} model checkpoint(s)")
    with st.expander("View Available Checkpoints"):
        for ckpt in sorted(checkpoint_files):
            st.write(f"- `{ckpt}`")

    st.subheader("üîÆ Generate Results")

    # Add softmax toggle
    col1, col2 = st.columns([2, 1])
    with col1:
        use_softmax = st.checkbox(
            "Apply Softmax Activation",
            value=True,
            help="Apply softmax to the model output for probability distribution. Uncheck for raw logits.",
        )
    with col2:
        st.write("")  # Spacing

    if st.button("üöÄ Run Inference", type="primary"):
        try:
            progress_bar = st.progress(0)
            status_text = st.empty()

            status_text.text("üîÆ Running inference...")
            progress_bar.progress(25)

            config_file = f"{config['project_name']}.yaml"

            # Ensure output directory exists
            os.makedirs(config["output_save_path"], exist_ok=True)

            progress_bar.progress(50)

            # Call inference function and store the returned plot path
            plot_path = plot_embeddings(
                config_file,
                config["n_cols"],
                config["n_rows"],
                save_path=config["output_save_path"],
                with_softmax=use_softmax,
            )

            progress_bar.progress(100)
            status_text.text("‚úÖ Inference completed successfully!")

            # Store the plot path in session state
            st.session_state.inference_plot_path = plot_path
            st.session_state.inference_done = True
            st.success("üéâ Inference completed!")

        except Exception as e:
            st.error(f"‚ùå Error during inference: {str(e)}")

    # Display results if inference has been completed
    if st.session_state.inference_done and st.session_state.inference_plot_path:
        display_results(st.session_state.inference_plot_path)


def display_results(plot_path):
    """Display generated inference results

    Args:
        plot_path: Path to the inference result image
    """
    st.divider()
    st.subheader("üìà Inference Results")

    if plot_path and os.path.exists(plot_path):
        st.success("‚úÖ Inference completed successfully!")
        st.write(f"**Output:** `{os.path.basename(plot_path)}`")

        # Display the inference image in full width
        st.image(plot_path, width="stretch")

        # Add download button centered below the image
        _, col2, _ = st.columns([1, 2, 1])
        with col2, open(plot_path, "rb") as file:
            st.download_button(
                label="üì• Download Result",
                data=file,
                file_name=os.path.basename(plot_path),
                mime="image/png",
                width="stretch",
                type="primary",
            )
    else:
        st.info("‚ÑπÔ∏è No result image found. Run inference to generate results.")


def create_training_config(config):
    """Create a training configuration dictionary"""
    return {
        "seed": 42,
        "test_only": False,
        "accelerator": config.get("device", "cpu"),  # Use selected device
        "task": "binary",
        "data": {
            "data_dir": config["boxed_png_path"],  # Use boxed images for training
            "train_dir": config["boxed_png_path"],  # Use boxed images for training
            "data_loader": "RawPngLoader",
            "train_ratio": 0.8,
            "val_ratio": 0.1,
            "test_ratio": 0.1,
            "num_workers": 4,
            "augment": False,
            "image_size": 256,
            "labels_file": os.path.basename(config["labelling_path"]),
        },
        "wandb": {
            "project_name": "ghost-hunter-web",
            "run_name": "",
            "experiment_id": "1",
            "ex_description": config["project_name"],
        },
        "model": {
            "in_channels": 1,
            "batch_size": config["batch_size"],
            "model_name": "ThreeLayerCnn",
            "accuracy_metric": "cross_entropy",
        },
        "optimizer": {
            "optimizer": "adamw",
            "lr": config["learning_rate"],
            "weight_decay": 0.002,
            "momentum": 0.9,
            "betas": [0.9, 0.999],
        },
        "scheduler": {
            "scheduler": "plateau",
            "step_size": 30,
            "step_size_up": 1000,
            "patience": 2,
            "factor": 0.5,
            "min_lr": 3e-5,
            "max_lr": 5e-5,
            "T_max": 10,
            "gamma": 0.1,
        },
        "trainer": {
            "num_nodes": 1,
            "devices": 1,
            "max_epochs": config["max_epochs"],
            "log_dir": "./logs",
            "log_every_n_steps": 100,
            "load_path": "",
            "resume_from": False,
            "checkpoint_dir": f"{config['project_name']}/",
            "wandb_logging": False,
        },
        "test": {
            "load_path": f"{config['project_name']}/",
        },
    }


if __name__ == "__main__":
    main()
